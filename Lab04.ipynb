{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab04-1\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Cost: ', 812.61072, '\\nPrediction:\\n', array([ 137.83509827,  148.21057129,  154.9763031 ,  171.14160156,\n",
      "        106.43566895], dtype=float32))\n",
      "(200, 'Cost: ', 70.869522, '\\nPrediction:\\n', array([ 161.2350769 ,  177.54801941,  183.25393677,  201.98561096,\n",
      "        129.07276917], dtype=float32))\n",
      "(400, 'Cost: ', 64.033318, '\\nPrediction:\\n', array([ 160.62809753,  177.96617126,  183.0705719 ,  201.83256531,\n",
      "        129.63874817], dtype=float32))\n",
      "(600, 'Cost: ', 57.895477, '\\nPrediction:\\n', array([ 160.05360413,  178.36206055,  182.89717102,  201.68684387,\n",
      "        130.17541504], dtype=float32))\n",
      "(800, 'Cost: ', 52.383923, '\\nPrediction:\\n', array([ 159.50985718,  178.73687744,  182.73312378,  201.54798889,\n",
      "        130.68431091], dtype=float32))\n",
      "(1000, 'Cost: ', 47.434731, '\\nPrediction:\\n', array([ 158.99525452,  179.09172058,  182.57804871,  201.41574097,\n",
      "        131.16691589], dtype=float32))\n",
      "(1200, 'Cost: ', 42.989899, '\\nPrediction:\\n', array([ 158.50820923,  179.4276123 ,  182.43139648,  201.28964233,\n",
      "        131.62458801], dtype=float32))\n",
      "(1400, 'Cost: ', 38.997746, '\\nPrediction:\\n', array([ 158.04728699,  179.74559021,  182.29270935,  201.16946411,\n",
      "        132.05865479], dtype=float32))\n",
      "(1600, 'Cost: ', 35.411972, '\\nPrediction:\\n', array([ 157.61116028,  180.04658508,  182.16163635,  201.05485535,\n",
      "        132.47035217], dtype=float32))\n",
      "(1800, 'Cost: ', 32.190514, '\\nPrediction:\\n', array([ 157.19842529,  180.33149719,  182.03770447,  200.94551086,\n",
      "        132.86087036], dtype=float32))\n",
      "(2000, 'Cost: ', 29.296337, '\\nPrediction:\\n', array([ 156.80793762,  180.60118103,  181.920578  ,  200.84120178,\n",
      "        133.23130798], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.], [93., 88., 93.],\n",
    "         [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Cost: ', 38860.586, '\\nPrediction:\\n', array([[-25.52147865],\n",
      "       [-24.20186234],\n",
      "       [-27.09520531],\n",
      "       [-29.40895844],\n",
      "       [-17.14146996]], dtype=float32))\n",
      "(200, 'Cost: ', 1.7117181, '\\nPrediction:\\n', array([[ 149.48501587],\n",
      "       [ 185.96151733],\n",
      "       [ 180.07698059],\n",
      "       [ 196.18226624],\n",
      "       [ 143.12684631]], dtype=float32))\n",
      "(400, 'Cost: ', 1.566412, '\\nPrediction:\\n', array([[ 149.57627869],\n",
      "       [ 185.89929199],\n",
      "       [ 180.10533142],\n",
      "       [ 196.19963074],\n",
      "       [ 143.0478363 ]], dtype=float32))\n",
      "(600, 'Cost: ', 1.4359465, '\\nPrediction:\\n', array([[ 149.66278076],\n",
      "       [ 185.84030151],\n",
      "       [ 180.13224792],\n",
      "       [ 196.21598816],\n",
      "       [ 142.9730835 ]], dtype=float32))\n",
      "(800, 'Cost: ', 1.3187603, '\\nPrediction:\\n', array([[ 149.74481201],\n",
      "       [ 185.78439331],\n",
      "       [ 180.15777588],\n",
      "       [ 196.23132324],\n",
      "       [ 142.90235901]], dtype=float32))\n",
      "(1000, 'Cost: ', 1.2135355, '\\nPrediction:\\n', array([[ 149.82255554],\n",
      "       [ 185.73139954],\n",
      "       [ 180.18199158],\n",
      "       [ 196.24575806],\n",
      "       [ 142.83543396]], dtype=float32))\n",
      "(1200, 'Cost: ', 1.1190197, '\\nPrediction:\\n', array([[ 149.89627075],\n",
      "       [ 185.6811676 ],\n",
      "       [ 180.20495605],\n",
      "       [ 196.25927734],\n",
      "       [ 142.7721405 ]], dtype=float32))\n",
      "(1400, 'Cost: ', 1.03411, '\\nPrediction:\\n', array([[ 149.96618652],\n",
      "       [ 185.63357544],\n",
      "       [ 180.22677612],\n",
      "       [ 196.27200317],\n",
      "       [ 142.71226501]], dtype=float32))\n",
      "(1600, 'Cost: ', 0.95783675, '\\nPrediction:\\n', array([[ 150.0324707 ],\n",
      "       [ 185.5884552 ],\n",
      "       [ 180.2474823 ],\n",
      "       [ 196.28390503],\n",
      "       [ 142.65565491]], dtype=float32))\n",
      "(1800, 'Cost: ', 0.88929582, '\\nPrediction:\\n', array([[ 150.09532166],\n",
      "       [ 185.54566956],\n",
      "       [ 180.26712036],\n",
      "       [ 196.29507446],\n",
      "       [ 142.6020813 ]], dtype=float32))\n",
      "(2000, 'Cost: ', 0.82771802, '\\nPrediction:\\n', array([[ 150.15490723],\n",
      "       [ 185.50511169],\n",
      "       [ 180.2857666 ],\n",
      "       [ 196.30554199],\n",
      "       [ 142.55142212]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab04-2\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6, 3), array([[  73.,   80.,   75.],\n",
      "       [  93.,   88.,   93.],\n",
      "       [  89.,   91.,   90.],\n",
      "       [  96.,   98.,  100.],\n",
      "       [  73.,   66.,   70.],\n",
      "       [  53.,   46.,   55.]], dtype=float32), 6)\n",
      "((6, 1), array([[ 152.],\n",
      "       [ 185.],\n",
      "       [ 180.],\n",
      "       [ 196.],\n",
      "       [ 142.],\n",
      "       [ 101.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Cost: ', 20100.086, ' Prediction: ', array([[ 15.35308552],\n",
      "       [ 25.62049103],\n",
      "       [ 21.43587303],\n",
      "       [ 23.02159691],\n",
      "       [ 21.90162849],\n",
      "       [ 17.10383415]], dtype=float32))\n",
      "(200, 'Cost: ', 8.3949156, ' Prediction: ', array([[ 148.66400146],\n",
      "       [ 185.44537354],\n",
      "       [ 179.12652588],\n",
      "       [ 194.69778442],\n",
      "       [ 143.74395752],\n",
      "       [ 106.79155731]], dtype=float32))\n",
      "(400, 'Cost: ', 7.5125647, ' Prediction: ', array([[ 148.91462708],\n",
      "       [ 185.3245697 ],\n",
      "       [ 179.22923279],\n",
      "       [ 194.75970459],\n",
      "       [ 143.58781433],\n",
      "       [ 106.54949951]], dtype=float32))\n",
      "(600, 'Cost: ', 6.7393198, ' Prediction: ', array([[ 149.14916992],\n",
      "       [ 185.2116394 ],\n",
      "       [ 179.32540894],\n",
      "       [ 194.81732178],\n",
      "       [ 143.44213867],\n",
      "       [ 106.32262421]], dtype=float32))\n",
      "(800, 'Cost: ', 6.0617266, ' Prediction: ', array([[ 149.36860657],\n",
      "       [ 185.10601807],\n",
      "       [ 179.41549683],\n",
      "       [ 194.87084961],\n",
      "       [ 143.30625916],\n",
      "       [ 106.10998535]], dtype=float32))\n",
      "(1000, 'Cost: ', 5.4677296, ' Prediction: ', array([[ 149.57402039],\n",
      "       [ 185.00733948],\n",
      "       [ 179.49992371],\n",
      "       [ 194.92066956],\n",
      "       [ 143.17958069],\n",
      "       [ 105.91065216]], dtype=float32))\n",
      "(1200, 'Cost: ', 4.9470119, ' Prediction: ', array([[ 149.76625061],\n",
      "       [ 184.91508484],\n",
      "       [ 179.57902527],\n",
      "       [ 194.96694946],\n",
      "       [ 143.06147766],\n",
      "       [ 105.72377777]], dtype=float32))\n",
      "(1400, 'Cost: ', 4.4904766, ' Prediction: ', array([[ 149.94612122],\n",
      "       [ 184.8288269 ],\n",
      "       [ 179.65309143],\n",
      "       [ 195.0098877 ],\n",
      "       [ 142.9513855 ],\n",
      "       [ 105.54855347]], dtype=float32))\n",
      "(1600, 'Cost: ', 4.0901022, ' Prediction: ', array([[ 150.11447144],\n",
      "       [ 184.74821472],\n",
      "       [ 179.72253418],\n",
      "       [ 195.04977417],\n",
      "       [ 142.84880066],\n",
      "       [ 105.38424683]], dtype=float32))\n",
      "(1800, 'Cost: ', 3.7389233, ' Prediction: ', array([[ 150.27204895],\n",
      "       [ 184.6729126 ],\n",
      "       [ 179.78762817],\n",
      "       [ 195.08680725],\n",
      "       [ 142.75328064],\n",
      "       [ 105.23016357]], dtype=float32))\n",
      "(2000, 'Cost: ', 3.4308326, ' Prediction: ', array([[ 150.41949463],\n",
      "       [ 184.60250854],\n",
      "       [ 179.84860229],\n",
      "       [ 195.12112427],\n",
      "       [ 142.66427612],\n",
      "       [ 105.08563232]], dtype=float32))\n",
      "('Your score will be ', array([[ 189.11587524]], dtype=float32))\n",
      "('Other scores will be ', array([[ 147.14810181],\n",
      "       [ 180.08770752]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Set up feed_dict variables inside the loop.\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], \n",
    "       feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \n",
    "                  \" Prediction: \", hy_val)\n",
    "\n",
    "\n",
    "# Ask my score\n",
    "print(\"Your score will be \", sess.run(hypothesis, \n",
    "           feed_dict={X: [[100, 70, 101]]}))\n",
    "\n",
    "print(\"Other scores will be \", sess.run(hypothesis, \n",
    "           feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train batch(skip)\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(\n",
    "   ['data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "# record_defaults : data type\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "   tf.train.batch([xy[0:-1], xy[-1:]], batch_size=2)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Field 0 in record 0 is not a valid float: # EXAM1\n",
      "\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], field_delim=\",\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderReadV2:1, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3)]]\n",
      "\t [[Node: DecodeCSV/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_10_DecodeCSV\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_8_batch_1/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\n\t [[Node: batch_1 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_1/fifo_queue, batch_1/n)]]\n\nCaused by op u'batch_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/junhyun/junhyunenv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-02d54508a803>\", line 14, in <module>\n    train_x_batch, train_y_batch =    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=2)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 919, in batch\n    name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 716, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_8_batch_1/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\n\t [[Node: batch_1 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_1/fifo_queue, batch_1/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c7e543d0576c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# bring data as batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     cost_val, hy_val, _ = sess.run(\n\u001b[1;32m     14\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_8_batch_1/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\n\t [[Node: batch_1 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_1/fifo_queue, batch_1/n)]]\n\nCaused by op u'batch_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/junhyun/junhyunenv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-02d54508a803>\", line 14, in <module>\n    train_x_batch, train_y_batch =    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=2)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 919, in batch\n    name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 716, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_8_batch_1/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\n\t [[Node: batch_1 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_1/fifo_queue, batch_1/n)]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    # bring data as batch\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], \n",
    "       feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \n",
    "                   \"\\nPrediction:\\n\", hy_val)\n",
    "# just use as a convention\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow kernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
